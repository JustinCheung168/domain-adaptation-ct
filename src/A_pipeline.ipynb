{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2bec9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import ResNetConfig\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import transformers\n",
    "from torchvision import transforms\n",
    "from branched_resnet import ResNetForMultiLabel\n",
    "from branched_resnet import OrganAMNISTDataset, compute_metrics, train_model\n",
    "import random\n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21076a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1df280ad530>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SET SEEDS\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7924dd",
   "metadata": {},
   "source": [
    "#### Import NPZ by concatenating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "880ff3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def import_data(directory, save_path=None, save=False):\n",
    "\n",
    "    data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.npz'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            loaded_data = np.load(file_path)\n",
    "            data.append(loaded_data)\n",
    "\n",
    "    # concatenate the data from all files\n",
    "    all_data = {}\n",
    "    for key in data[0].keys():\n",
    "        all_data[key] = np.concatenate([d[key] for d in data], axis=0)\n",
    "\n",
    "    # check the shape of the concatenated data\n",
    "    for key, value in all_data.items():\n",
    "        print(f\"{key}: {value.shape}\")  \n",
    "\n",
    "    if save:\n",
    "        if save_path is None:\n",
    "            save_path = f'datasets/{directory}_concatenated_data.npz'\n",
    "        np.savez(save_path, **all_data)\n",
    "        print(f\"Data saved to {save_path}\")\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708a6047",
   "metadata": {},
   "source": [
    "### Image normalizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed459e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image, mean=0.5, std=0.5):\n",
    "    \"\"\"\n",
    "    Normalize an image tensor to have a mean and standard deviation.\n",
    "    \"\"\"\n",
    "    return (image - mean) / std\n",
    "\n",
    "def normalize_images(images, mean=0.5, std=0.5):\n",
    "    \"\"\"\n",
    "    Normalize a list of images.\n",
    "    \"\"\"\n",
    "    return [normalize_image(image, mean, std) for image in images]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb4c6db",
   "metadata": {},
   "source": [
    "### Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f44d030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modified CustomImageDataset Loader\n",
    "\n",
    "class ModifiedCustomImageDataset(Dataset):\n",
    "    def __init__(self, images, labels1,  transform=None):\n",
    "        self.images = images \n",
    "        self.labels1 = labels1\n",
    "\n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Lambda(lambda x: x.repeat(3, 1, 1))  # Grayscale to 3-channel\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx].astype(np.float32)\n",
    "        label1 = int(self.labels1[idx])\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return {\n",
    "            \"pixel_values\": img,\n",
    "            \"labels\": int(label1) if torch.is_tensor(label1) else label1,\n",
    "        }\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55df27b7",
   "metadata": {},
   "source": [
    "#### Preprocessing functions for single distortion and multi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c8c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modified\n",
    "\n",
    "def validation_preprocess_data(data, key='original'):\n",
    "    \"\"\"\n",
    "    Modified from sam's implementation to preprocess 1 set of images. \n",
    "    \n",
    "    key : str (distortion name)\n",
    "    \"\"\"\n",
    "    keys = data.files \n",
    "    print(f'\\nGenerating {key} validataion set')\n",
    "    \n",
    "    images = data[key]\n",
    "    labels = data['label']\n",
    "    \n",
    "    normalized_images = []\n",
    "    for image in images:\n",
    "        normalized_images.append(normalize_images(image))\n",
    "        \n",
    "    labels = np.array(labels)\n",
    "    normalized_images = np.array(normalized_images)\n",
    "    \n",
    "    \n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Images shape: {normalized_images.shape}\")\n",
    "\n",
    "    dataset = ModifiedCustomImageDataset(images=normalized_images, labels1=labels)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96678fde",
   "metadata": {},
   "source": [
    "#### Preprocess data into distinct sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cfb27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 'Uniform_Noise', 'Rotate_90deg']\n",
      "\n",
      "Generating Rotate_90deg validataion set\n",
      "Labels shape: (1, 6491, 1)\n",
      "Images shape: (1, 6491, 224, 224)\n",
      "\n",
      "Generating original validataion set\n",
      "Labels shape: (1, 6491, 1)\n",
      "Images shape: (1, 6491, 224, 224)\n",
      "\n",
      "Generating Uniform_Noise validataion set\n",
      "Labels shape: (1, 6491, 1)\n",
      "Images shape: (1, 6491, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "val_set_loaded = np.load('val_concatenated_data.npz')\n",
    "key_list = [key for key in val_set_loaded.files if key != 'label']\n",
    "print(key_list)\n",
    "\n",
    "val_rotate_set = validation_preprocess_data(val_set_loaded, 'Rotate_90deg')\n",
    "val_original_set = validation_preprocess_data(val_set_loaded, 'original')\n",
    "val_noise_set = validation_preprocess_data(val_set_loaded, 'Uniform_Noise')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_set_loaded = np.load('training_concatenated_data.npz')\n",
    "train_rotate_set = validation_preprocess_data(train_set_loaded, 'Rotate_90deg')\n",
    "train_original_set = validation_preprocess_data(train_set_loaded, 'original')\n",
    "train_noise_set = validation_preprocess_data(train_set_loaded, 'Uniform_Noise')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41e8ed8",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84e9ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 103,683\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 324,100\n",
      "  Number of trainable parameters = 24,562,763\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b09c58b01584995a0b4c7fdf3511b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    }
   ],
   "source": [
    "output_path = os.path.join('C_model', 'results')\n",
    "\n",
    "\n",
    "config = ResNetConfig()\n",
    "model = ResNetForMultiLabel(config)\n",
    "\n",
    "print(\"Starting training\")\n",
    "trainer = train_model(\n",
    "    train_dataset=train_original_set,\n",
    "    eval_dataset=val_original_set,\n",
    "    model=model,\n",
    "    output_dir=output_path,  # Checkpoints will go here\n",
    "    num_epochs=100,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"Saving final model\")\n",
    "trainer.save_model(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec52d043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CUDA is available!\n",
      "Using GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"✅ CUDA is available!\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"❌ CUDA is NOT available. Using CPU.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20328f28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
