epoch,grad_norm,learning_rate,step,train_loss
1.0,42.56991195678711,0.06862745098039216,17,1.6785
1.0,0.14065510597302505,0.5067437379576107,0.02242014742014742,0.33631713554987214,0.0,1.8949404954910278,0.01278682781572955,0.25337186897880537,0.09090909090909091,0.5,15.9552,32.529,1.065,,,17,
1.0,0.14065510597302505,0.5067437379576107,0.02242014742014742,0.33631713554987214,0.0,1.8949404954910278,0.01278682781572955,0.25337186897880537,0.09090909090909091,0.5,15.9552,32.529,1.065,,,17,
2.0,,,,,,,,,,,,,,35.005126953125,0.03529411764705883,34,1.5794
2.0,0.14258188824662812,0.5067437379576107,0.02478908570279129,0.33631713554987214,0.1111111111111111,1.8392317295074463,0.10372060372060372,0.25337186897880537,0.09208972845336481,0.5,17.1453,30.271,0.992,,,34,
2.0,0.14258188824662812,0.5067437379576107,0.02478908570279129,0.33631713554987214,0.1111111111111111,1.8392317295074463,0.10372060372060372,0.25337186897880537,0.09208972845336481,0.5,17.1453,30.271,0.992,,,34,
3.0,,,,,,,,,,,,,,31.350051879882812,0.00196078431372549,51,1.5572
3.0,0.14065510597302505,0.5067437379576107,0.02633241848928123,0.33631713554987214,0.4444444444444444,1.789739966392517,0.02033860875966139,0.25337186897880537,0.09077970597273212,0.5,18.2608,28.421,0.931,,,51,
3.0,0.14065510597302505,0.5067437379576107,0.02633241848928123,0.33631713554987214,0.4444444444444444,1.789739966392517,0.02033860875966139,0.25337186897880537,0.09077970597273212,0.5,18.2608,28.421,0.931,,,51,
3.0,,,,,,,,,,,,,,,,51,0.0,1.605046926760206,177.4892,8.772,0.287
