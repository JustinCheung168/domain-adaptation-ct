{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TOXLi8LE9Yr"
      },
      "outputs": [],
      "source": [
        "from enum import Enum\n",
        "from typing import Optional, Tuple, List\n",
        "from multiprocessing import Pool\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt # Image display\n",
        "from medmnist import OrganAMNIST # Dataset\n",
        "import numpy as np\n",
        "from scipy.fft import fft, ifft, fftshift, ifftshift, fftfreq\n",
        "from scipy.ndimage import rotate\n",
        "from skimage.data import shepp_logan_phantom\n",
        "from skimage.transform import radon, iradon, iradon_sart, rescale, resize\n",
        "\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from numpy.random import RandomState\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.utils.data as data\n",
        "from torchvision.transforms.functional import pil_to_tensor\n",
        "\n",
        "from tqdm import tqdm # Progress bar\n",
        "\n",
        "# Custom code from this project\n",
        "from src.preprocess.ct.corruption import SinogramCorruptor\n",
        "from src.preprocess.ct.padder import Padder, SymmetricPadder, ShiftPadder\n",
        "from src.preprocess.ct.projector import Projector, KernelType\n",
        "from src.visualize.imshow_gray import ImShowGray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFMRm6AvdpIV",
        "outputId": "c15d62c2-0e79-450a-950b-2e0fcc393f7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://zenodo.org/records/10519652/files/organamnist_224.npz?download=1 to /root/.medmnist/organamnist_224.npz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 12.5M/1.80G [00:22<54:48, 545kB/s]  \n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "\n                Automatic download failed! Please download organamnist_224.npz manually.\n                1. [Optional] Check your network connection: \n                    Go to https://github.com/MedMNIST/MedMNIST/ and find the Zenodo repository\n                2. Download the npz file from the Zenodo repository or its Zenodo data link: \n                    https://zenodo.org/records/10519652/files/organamnist_224.npz?download=1\n                3. [Optional] Verify the MD5: \n                    50747347e05c87dd3aaf92c49f9f3170\n                4. Put the npz file under your MedMNIST root folder: \n                    /root/.medmnist\n                ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/medmnist/dataset.py:106\u001b[0m, in \u001b[0;36mMedMNIST.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download_url\n\u001b[0;32m--> 106\u001b[0m     \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize_flag\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflag\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize_flag\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.npz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmd5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMD5\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize_flag\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchvision/datasets/utils.py:132\u001b[0m, in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m url \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m fpath)\n\u001b[0;32m--> 132\u001b[0m     \u001b[43m_urlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchvision/datasets/utils.py:30\u001b[0m, in \u001b[0;36m_urlretrieve\u001b[0;34m(url, filename, chunk_size)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh, tqdm(total\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mlength, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m chunk \u001b[38;5;241m:=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     31\u001b[0m         fh\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:473\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    472\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 473\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/socket.py:718\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m   datasets[split] \u001b[38;5;241m=\u001b[39m OrganAMNIST(split\u001b[38;5;241m=\u001b[39msplit, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m224\u001b[39m, root\u001b[38;5;241m=\u001b[39mMEDMNIST_LOCAL_DIR)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 9\u001b[0m   datasets[split] \u001b[38;5;241m=\u001b[39m \u001b[43mOrganAMNIST\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(datasets[split]), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages in the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/medmnist/dataset.py:56\u001b[0m, in \u001b[0;36mMedMNIST.__init__\u001b[0;34m(self, split, transform, target_transform, download, as_rgb, root, size, mmap_mode)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to setup the default `root` directory. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease specify and create the `root` directory manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m     )\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m     59\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize_flag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m ):\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m You can set `download=True` to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     63\u001b[0m     )\n",
            "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/medmnist/dataset.py:113\u001b[0m, in \u001b[0;36mMedMNIST.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m     download_url(\n\u001b[1;32m    107\u001b[0m         url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize_flag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    108\u001b[0m         root\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot,\n\u001b[1;32m    109\u001b[0m         filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize_flag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    110\u001b[0m         md5\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMD5\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize_flag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    111\u001b[0m     )\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124m        Automatic download failed! Please download \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize_flag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npz manually.\u001b[39m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124m        1. [Optional] Check your network connection: \u001b[39m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124m            Go to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHOMEPAGE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and find the Zenodo repository\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124m        2. Download the npz file from the Zenodo repository or its Zenodo data link: \u001b[39m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize_flag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124m        3. [Optional] Verify the MD5: \u001b[39m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMD5\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize_flag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124m        4. Put the npz file under your MedMNIST root folder: \u001b[39m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    125\u001b[0m     )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: \n                Automatic download failed! Please download organamnist_224.npz manually.\n                1. [Optional] Check your network connection: \n                    Go to https://github.com/MedMNIST/MedMNIST/ and find the Zenodo repository\n                2. Download the npz file from the Zenodo repository or its Zenodo data link: \n                    https://zenodo.org/records/10519652/files/organamnist_224.npz?download=1\n                3. [Optional] Verify the MD5: \n                    50747347e05c87dd3aaf92c49f9f3170\n                4. Put the npz file under your MedMNIST root folder: \n                    /root/.medmnist\n                "
          ]
        }
      ],
      "source": [
        "MEDMNIST_LOCAL_DIR = \"/data/.medmnist\"\n",
        "OUTPUTS_DIR = \"/data/ring_v2_preprocessed\"\n",
        "datasets = {}\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "for split in splits:\n",
        "  if os.path.exists(MEDMNIST_LOCAL_DIR):\n",
        "    datasets[split] = OrganAMNIST(split=split, size=224, root=MEDMNIST_LOCAL_DIR)\n",
        "  else:\n",
        "    datasets[split] = OrganAMNIST(split=split, size=224, download=True)\n",
        "    shutil.move(\"root/.medmnist\", MEDMNIST_LOCAL_DIR)\n",
        "  print(len(datasets[split]), f\"images in the {split} dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEIGffw2rNvS"
      },
      "outputs": [],
      "source": [
        "# Distortion Classes\n",
        "\n",
        "class RingArtifactUniformlyRandom:\n",
        "  \"\"\"\n",
        "  Simulate CT ring artifacts in an image.\n",
        "  No prior knowledge can be assumed about the world coordinates of the anatomy.\n",
        "  For each detector, apply a gain error of up to `gain_error_range`.\n",
        "  The ring may be shifted by an integer number of pixels, up to plus or minus `shift_range` many pixels in each direction.\n",
        "  \"\"\"\n",
        "  def __init__(self, shift_range: int, gain_error_range: Tuple[float, float]):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      shift_range: Maximum number of pixels by which to shift the ring.\n",
        "      gain_error_range: Maximum negative & positive gain error to apply to the ring. A value of 0.03 is treated as 3% gain error, for example.\n",
        "    \"\"\"\n",
        "    self.shift_range = shift_range\n",
        "    self.gain_error_range = gain_error_range\n",
        "\n",
        "  def __call__(self, img: Image.Image) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Note that this function generates random shift and gain error.\n",
        "    \"\"\"\n",
        "    # Min-max normalize, assuming all images can be in range 0-255.\n",
        "    # This helps keep the input to the Radon transform in a comparable\n",
        "    # range to the output from the inverse Radon transform.\n",
        "    img = np.asarray(img).astype(np.float32) / 255.0\n",
        "\n",
        "    # Draw random shift error.\n",
        "    shift_down = np.random.randint(-self.shift_range, self.shift_range+1)\n",
        "    shift_right = np.random.randint(-self.shift_range, self.shift_range+1)\n",
        "\n",
        "    # Pad the image so that when it is rotated during forward projection, no data is lost.\n",
        "    padder = ShiftPadder(shift_down=shift_down, shift_right=shift_right, arr_shape=img.shape, circumscribe=True)\n",
        "    img_pad = padder.pad(img)\n",
        "\n",
        "    # _ = ImShowGray.imshow(img_pad, title=\"Padded Image\", title_stats=True)\n",
        "\n",
        "    num_projections = max(img_pad.shape)*2\n",
        "    # Need 360 degree scanning to produce the full ring artifact instead of just half a ring.\n",
        "    theta = np.linspace(0., 360., num=num_projections, endpoint=False)\n",
        "\n",
        "    sinogram = radon(img_pad, theta=theta)\n",
        "\n",
        "    # Assume all detectors have a gain error.\n",
        "    faulty_detectors = list(range(sinogram.shape[0]))\n",
        "\n",
        "    # Draw random gain errors.\n",
        "    GAIN_MIN = 1.00 + self.gain_error_range[0]\n",
        "    # Assume the detector will not get more sensitive.\n",
        "    GAIN_MAX = 1.00 + self.gain_error_range[1]\n",
        "    print(f\"Gain range: {GAIN_MIN} to {GAIN_MAX}\")\n",
        "    faulty_detector_gains = ((np.random.random(sinogram.shape[0]) * (GAIN_MAX-GAIN_MIN)) + GAIN_MIN).tolist()\n",
        "\n",
        "    corruptor = SinogramCorruptor()\n",
        "    sinogram_corrupt = corruptor.create_multiplicative_ring_artifact(sinogram, detectors=faulty_detectors, factors=faulty_detector_gains)\n",
        "\n",
        "    img_recon_pad = iradon(sinogram, theta=theta, filter_name='ramp')\n",
        "    img_recon_pad_corrupt = iradon(sinogram_corrupt, theta=theta, filter_name='ramp')\n",
        "\n",
        "    img_recon = padder.unpad(img_recon_pad)\n",
        "    img_recon_corrupt = padder.unpad(img_recon_pad_corrupt)\n",
        "\n",
        "    # To keep the corruption without having the reconstruction error,\n",
        "    # take difference between reconstructed image with and without corruption\n",
        "    # to derive an image of just the corruption.\n",
        "    # Then, add this corruption back to the original image.\n",
        "    corruption = img_recon_corrupt - img_recon\n",
        "    img_corrupt = img + corruption\n",
        "\n",
        "    # _,_ = ImShowGray.imshow_diff(img_recon, img, titles=(\"Reconstructed\",\"Original\"), title_stats=True, title_window=True, window=[0, 1])\n",
        "    # _ = ImShowGray.imshow(sinogram, title=\"Sinogram\", title_stats=True)\n",
        "\n",
        "    # _,_ = ImShowGray.imshow_diff(img_recon_corrupt, img, titles=(\"Distorted Recon.\",\"Original\"), title_stats=True, title_window=True, window=[0, 1])\n",
        "    # _ = ImShowGray.imshow(sinogram_corrupt, title=\"Distorted Sinogram\", title_stats=True)\n",
        "\n",
        "    # _,_ = ImShowGray.imshow_diff(img_corrupt, img, titles=(\"Distorted\",\"Original\"), title_stats=True, title_window=True, window=[0, 1])\n",
        "\n",
        "    return np.asarray(img_corrupt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4N24kOC-PuN"
      },
      "outputs": [],
      "source": [
        "# Visualization\n",
        "\n",
        "def show_distortion_comparison_ring(dataset, transforms_dict, indices):\n",
        "  \"\"\"\n",
        "  Show the original image and its distortions side by side.\n",
        "\n",
        "  Parameters:\n",
        "  - dataset: OrganMNIST dataset (PIL images, transform=None)\n",
        "  - transforms_dict: dict of {name: transform}\n",
        "  - indices: list of dataset indices to save\n",
        "  \"\"\"\n",
        "  num_imgs = len(indices)\n",
        "  num_transforms = len(transforms_dict)\n",
        "\n",
        "  plt.figure(figsize=(4 * (num_transforms + 1), 3 * num_imgs))\n",
        "\n",
        "  for row, idx in enumerate(indices):\n",
        "    raw_img, label = dataset[idx]\n",
        "    raw_np = np.asarray(raw_img)\n",
        "\n",
        "    # Column 0: Original\n",
        "    plt.subplot(num_imgs, num_transforms + 1, row * (num_transforms + 1) + 1)\n",
        "    plt.imshow(raw_np, cmap='gray')\n",
        "    plt.title(f\"Original\\nImage: {idx}\\nLabel: {label}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Distorted columns\n",
        "    for col, (name, transform) in enumerate(transforms_dict.items(), start=1):\n",
        "      distorted_np = transform(raw_img)\n",
        "      plt.subplot(num_imgs, num_transforms + 1, row * (num_transforms + 1) + col + 1)\n",
        "      plt.imshow(distorted_np, cmap='gray')\n",
        "      plt.title(f\"{name}\")\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gxFBy0erNzo"
      },
      "outputs": [],
      "source": [
        "def save_distorted_subset_to_npz_ring(dataset, transforms_dict, indices, output_root, filename=\"subset_all_in_one.npz\"):\n",
        "  \"\"\"\n",
        "  Save a subset of images (original + distortions) into one .npz file.\n",
        "\n",
        "  Parameters:\n",
        "  - dataset: OrganMNIST dataset (PIL images, transform=None)\n",
        "  - split_name: \"train\", \"val\", or \"test\"\n",
        "  - transforms_dict: dict of {name: transform}\n",
        "  - indices: list of dataset indices to save\n",
        "  - output_root: folder to save the single .npz file\n",
        "  \"\"\"\n",
        "  os.makedirs(output_root, exist_ok=True)\n",
        "  save_path = os.path.join(output_root, filename)\n",
        "\n",
        "  original_list = []\n",
        "  label_list = []\n",
        "  distortion_lists = {name.replace(\" \", \"_\").replace(\"°\", \"deg\"): [] for name in transforms_dict}\n",
        "\n",
        "  with open(f\"{filename}.log\", \"w\") as log_file:\n",
        "    for idx in tqdm(indices, file=log_file):\n",
        "      # Modified.\n",
        "      raw_img, label = dataset[idx]\n",
        "      orig_np = np.asarray(raw_img).astype(np.float32) / 255.0\n",
        "      original_list.append(orig_np)\n",
        "      label_list.append(label)\n",
        "\n",
        "      for name, transform in transforms_dict.items():\n",
        "        key = name.replace(\" \", \"_\").replace(\"°\", \"deg\")\n",
        "        transformed_np = transform(raw_img)\n",
        "        distortion_lists[key].append(transformed_np)\n",
        "\n",
        "  # Build final save dict\n",
        "  save_dict = {\n",
        "    \"original\": np.stack(original_list),\n",
        "    \"label\": np.array(label_list)\n",
        "  }\n",
        "  for key, value_list in distortion_lists.items():\n",
        "    save_dict[key] = np.stack(value_list)\n",
        "\n",
        "  np.savez_compressed(save_path, **save_dict)\n",
        "  print(f\"\\nSaved {len(indices)} distorted images to single file: {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPff2VW9DaEz"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        },
        "id": "7PwkiP2p-3KF",
        "outputId": "11db7338-3051-4073-b978-7284b6516623"
      },
      "outputs": [],
      "source": [
        "# Load PIL image version (no transform)\n",
        "distortions = {\n",
        "  \"Ring Artifact v1\": RingArtifactUniformlyRandom(shift_range = 10, gain_error_range = (-0.1, 0.1)),\n",
        "}\n",
        "\n",
        "# Random indices\n",
        "train_subset_indices = np.random.choice(10000, 3)\n",
        "# test_subset_indices = np.random.choice(10000, 4)\n",
        "# val_subset_indices = np.random.choice(10000, 4)\n",
        "\n",
        "# Display the images\n",
        "show_distortion_comparison_ring(datasets[\"train\"], distortions, indices=train_subset_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Nah1k3XlCzGG",
        "outputId": "f0f72a68-08e8-4488-b3a5-1b42183f976a"
      },
      "outputs": [],
      "source": [
        "# Show difference image as well\n",
        "for i in train_subset_indices:\n",
        "  img = datasets[\"train\"][i][0]\n",
        "\n",
        "  distorter = RingArtifactUniformlyRandom(\n",
        "    # Choosing a fairly small shift to emulate relative displacement of patient on table.\n",
        "    # Displacement of anatomy relative to patient axis is not in scope.\n",
        "    shift_range = 10,\n",
        "    # Individual pixel gain error is \"typically within a few percent\", according to:\n",
        "    # Blaj, Gabriel. \"Dead-time correction for spectroscopic photon-counting pixel detectors.\" Synchrotron Radiation 26.5 (2019): 1621-1630.\n",
        "    gain_error_range = (-0.1, 0.1),\n",
        "  )\n",
        "\n",
        "  img_corrupt = distorter(img)\n",
        "\n",
        "  img_normalized = np.asarray(img).astype(np.float32) / 255.0\n",
        "  _,_ = ImShowGray.imshow_diff(img_corrupt, img_normalized, titles=(\"Distorted\",\"Original\"), title_stats=True, title_window=True, window=[0, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLxkl_G4KRmb"
      },
      "source": [
        "## Let's split up the work starting here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wm2JZY2Tt-VT"
      },
      "outputs": [],
      "source": [
        "jobs = [\n",
        "  {\n",
        "    \"seed\": 1,\n",
        "    \"split\": \"train\",\n",
        "    \"start\": 0,\n",
        "    \"stop\": 5000,\n",
        "    \"filename\": \"train_subset_first_5000_RingArtifactv1_images.npz\"\n",
        "  },\n",
        "  {\n",
        "    \"seed\": 2,\n",
        "    \"split\": \"train\",\n",
        "    \"start\": 5000,\n",
        "    \"stop\": 10000,\n",
        "    \"filename\": \"train_subset_second_5000_RingArtifactv1_images.npz\"\n",
        "  },\n",
        "  {\n",
        "    \"seed\": 3,\n",
        "    \"split\": \"train\",\n",
        "    \"start\": 10000,\n",
        "    \"stop\": 15000,\n",
        "    \"filename\": \"train_subset_third_5000_RingArtifactv1_images.npz\"\n",
        "  },\n",
        "  {\n",
        "    \"seed\": 4,\n",
        "    \"split\": \"train\",\n",
        "    \"start\": 15000,\n",
        "    \"stop\": 20000,\n",
        "    \"filename\": \"train_subset_fourth_5000_RingArtifactv1_images.npz\"\n",
        "  },\n",
        "  {\n",
        "    \"seed\": 5,\n",
        "    \"split\": \"train\",\n",
        "    \"start\": 20000,\n",
        "    \"stop\": 25000,\n",
        "    \"filename\": \"train_subset_fifth_5000_RingArtifactv1_images.npz\"\n",
        "  },\n",
        "  {\n",
        "    \"seed\": 6,\n",
        "    \"split\": \"train\",\n",
        "    \"start\": 25000,\n",
        "    \"stop\": 30000,\n",
        "    \"filename\": \"train_subset_sixth_5000_RingArtifactv1_images.npz\"\n",
        "  },\n",
        "  {\n",
        "    \"seed\": 7,\n",
        "    \"split\": \"train\",\n",
        "    \"start\": 30000,\n",
        "    \"stop\": 34561,\n",
        "    \"filename\": \"train_subset_last_4561_RingArtifactv1_images.npz\"\n",
        "  },\n",
        "  {\n",
        "    \"seed\": 8,\n",
        "    \"split\": \"val\",\n",
        "    \"start\": 0,\n",
        "    \"stop\": 5000,\n",
        "    \"filename\": \"val_subset_first_5000_RingArtifactv1_images.npz\"\n",
        "  },\n",
        "  {\n",
        "    \"seed\": 9,\n",
        "    \"split\": \"val\",\n",
        "    \"start\": 5000,\n",
        "    \"stop\": 6491,\n",
        "    \"filename\": \"val_subset_last_1491_RingArtifactv1_images.npz\"\n",
        "  },\n",
        "  {\n",
        "    \"seed\": 10,\n",
        "    \"split\": \"test\",\n",
        "    \"start\": 0,\n",
        "    \"stop\": 5000,\n",
        "    \"filename\": \"test_subset_first_5000_RingArtifactv1_images.npz\"\n",
        "  },\n",
        "  {\n",
        "    \"seed\": 11,\n",
        "    \"split\": \"test\",\n",
        "    \"start\": 5000,\n",
        "    \"stop\": 10000,\n",
        "    \"filename\": \"test_subset_second_5000_RingArtifactv1_images.npz\"\n",
        "  },\n",
        "  {\n",
        "    \"seed\": 12,\n",
        "    \"split\": \"test\",\n",
        "    \"start\": 10000,\n",
        "    \"stop\": 15000,\n",
        "    \"filename\": \"test_subset_third_5000_RingArtifactv1_images.npz\"\n",
        "  },\n",
        "  {\n",
        "    \"seed\": 13,\n",
        "    \"split\": \"test\",\n",
        "    \"start\": 15000,\n",
        "    \"stop\": 17778,\n",
        "    \"filename\": \"test_subset_last_2778_RingArtifactv1_images.npz\"\n",
        "  },\n",
        "]\n",
        "\n",
        "def wrap_save_distorted_subset_to_npz_ring(job):\n",
        "  np.random.seed(job[\"seed\"])\n",
        "  save_distorted_subset_to_npz_ring(\n",
        "    dataset=datasets[job[\"split\"]],\n",
        "    transforms_dict=distortions,\n",
        "    indices=np.arange(job[\"start\"],job[\"stop\"]),\n",
        "    output_root=os.path.join(OUTPUTS_DIR, \"RingArtifactv1_npz\"),\n",
        "    filename=job[\"filename\"]\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eM5jheOyEMV0"
      },
      "outputs": [],
      "source": [
        "# First 4 jobs\n",
        "with Pool(processes=4) as pool:\n",
        "    pool.map(wrap_save_distorted_subset_to_npz_ring, jobs[0:4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with Pool(processes=4) as pool:\n",
        "    pool.map(wrap_save_distorted_subset_to_npz_ring, jobs[4:8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipHa-rm-EMgI"
      },
      "outputs": [],
      "source": [
        "with Pool(processes=4) as pool:\n",
        "    pool.map(wrap_save_distorted_subset_to_npz_ring, jobs[8:12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnfSkcG3EMkl"
      },
      "outputs": [],
      "source": [
        "with Pool(processes=4) as pool:\n",
        "    pool.map(wrap_save_distorted_subset_to_npz_ring, jobs[12:13])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiTsR_CgHKJN",
        "outputId": "0f801b7e-ca7e-4614-da3e-26ef32227eee"
      },
      "outputs": [],
      "source": [
        "npz_path = os.path.join(OUTPUTS_DIR, \"RingArtifactv1_npz/train_subset_first_5000_RingArtifactv1_images.npz\")\n",
        "distorted_images = np.load(npz_path)\n",
        "\n",
        "print(\"Available keys in the file:\", distorted_images.files)\n",
        "\n",
        "# Inspect shapes and types\n",
        "for key in distorted_images.files:\n",
        "    print(f\"{key}: shape={distorted_images[key].shape}, dtype={distorted_images[key].dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z66wV_lHHKK7"
      },
      "outputs": [],
      "source": [
        "def show_npz_image_set(npz_path, index=0):\n",
        "    \"\"\"\n",
        "    Display all images (original + distortions) at a given index from a .npz file.\n",
        "\n",
        "    Parameters:\n",
        "    - npz_path: Path to the .npz file\n",
        "    - index: Index of the image to display\n",
        "    \"\"\"\n",
        "    data = np.load(npz_path)\n",
        "    keys = [k for k in data.files if k != \"label\"]\n",
        "    num_images = len(keys)\n",
        "\n",
        "    plt.figure(figsize=(3 * num_images, 3))\n",
        "    for i, key in enumerate(keys):\n",
        "        img = data[key][index]\n",
        "        plt.subplot(1, num_images, i + 1)\n",
        "        plt.imshow(img, cmap='gray')\n",
        "        plt.title(key)\n",
        "        plt.axis('off')\n",
        "\n",
        "    label = data[\"label\"][index].item() if \"label\" in data else \"N/A\"\n",
        "    plt.suptitle(f\"Label: {label}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    _,_ = ImShowGray.imshow_diff(data[\"Ring_Artifact_v1\"][index], data[\"original\"][index], titles=(\"Distorted\",\"Original\"), title_stats=True, title_window=True, window=[0, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34EdHerpBT-V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgNAISZvTTg7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44ykR401LVjU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
