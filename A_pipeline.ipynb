{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2bec9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import ResNetConfig\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import transformers\n",
    "from torchvision import transforms\n",
    "from resnet import ResNetForMultiLabel\n",
    "from resnet import OrganAMNISTDataset, compute_metrics, train_model, evaluate_model\n",
    "import random\n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21076a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x219085c7530>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SET SEEDS\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7924dd",
   "metadata": {},
   "source": [
    "#### Import NPZ by concatenating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "880ff3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def import_data(directory, save_path=None, save=False):\n",
    "\n",
    "    data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.npz'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            loaded_data = np.load(file_path)\n",
    "            data.append(loaded_data)\n",
    "\n",
    "    # concatenate the data from all files\n",
    "    all_data = {}\n",
    "    for key in data[0].keys():\n",
    "        all_data[key] = np.concatenate([d[key] for d in data], axis=0)\n",
    "\n",
    "    # check the shape of the concatenated data\n",
    "    for key, value in all_data.items():\n",
    "        print(f\"{key}: {value.shape}\")  \n",
    "\n",
    "    if save:\n",
    "        if save_path is None:\n",
    "            save_path = f'datasets/{directory}_concatenated_data.npz'\n",
    "        np.savez(save_path, **all_data)\n",
    "        print(f\"Data saved to {save_path}\")\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38629835",
   "metadata": {},
   "source": [
    "#### After combining the uniform noise + rotation + original, add in CT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b6762f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: (34561, 224, 224)\n",
      "label: (34561, 1)\n",
      "Uniform_Noise: (34561, 224, 224)\n",
      "Rotate_90deg: (34561, 224, 224)\n",
      "label: (34561, 1)\n",
      "Ring_Artifact_v1: (34561, 224, 224)\n",
      "original: (34561, 224, 224)\n",
      "label: (34561, 1)\n",
      "Uniform_Noise: (34561, 224, 224)\n",
      "Rotate_90deg: (34561, 224, 224)\n",
      "Ring_Artifact_v1: (34561, 224, 224)\n",
      "Data saved to training_concatenated_dataset_full.npz\n"
     ]
    }
   ],
   "source": [
    "#quick method to add new CT information into the full concat file. \n",
    "def combine_npz(npz_data, CT_directory, save_name, file_prefix='train'):\n",
    "\n",
    "    labels = ['label', 'Ring_Artifact_v1']\n",
    "    data = []\n",
    "    for filename in os.listdir(CT_directory):\n",
    "        if filename.startswith(file_prefix):\n",
    "                file_path = os.path.join(CT_directory, filename)\n",
    "                loaded_data = np.load(file_path)\n",
    "                data.append(loaded_data)\n",
    "    all_data = {}\n",
    "    for key in labels:\n",
    "        all_data[key] = np.concatenate([d[key] for d in data], axis=0)\n",
    "\n",
    "    for key, value in all_data.items():\n",
    "        print(f\"{key}: {value.shape}\")  \n",
    "    \n",
    "    npz_data['Ring_Artifact_v1'] = all_data['Ring_Artifact_v1']\n",
    "    \n",
    "    for key, value in npz_data.items():\n",
    "        print(f\"{key}: {value.shape}\")  \n",
    "        \n",
    "    np.savez(save_name, **npz_data)\n",
    "    print(f\"Data saved to {save_name}\")\n",
    "    \n",
    "    \n",
    "directory = 'Distorted_OrganAMNIST/RingArtifactv1_npz'\n",
    "training_data = import_data('Distorted_OrganAMNIST/UniformNoise_Rotate90_npz')\n",
    "# val_data = import_data('Distorted_OrganAMNIST/UniformNoise_Rotate90_val_dataset')\n",
    "# test_data = import_data('Distorted_OrganAMNIST/UniformNoise_Rotate90_test_dataset')\n",
    "\n",
    "combine_npz(training_data, directory, 'training_concatenated_dataset_full.npz', 'train')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708a6047",
   "metadata": {},
   "source": [
    "### Image normalizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed459e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image, mean=0.5, std=0.5):\n",
    "    \"\"\"\n",
    "    Normalize an image tensor to have a mean and standard deviation.\n",
    "    \"\"\"\n",
    "    return (image - mean) / std\n",
    "\n",
    "def normalize_images(images, mean=0.5, std=0.5):\n",
    "    \"\"\"\n",
    "    Normalize a list of images.\n",
    "    \"\"\"\n",
    "    return [normalize_image(image, mean, std) for image in images]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb4c6db",
   "metadata": {},
   "source": [
    "### Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f44d030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modified CustomImageDataset Loader\n",
    "\n",
    "class ModifiedCustomImageDataset(Dataset):\n",
    "    def __init__(self, images, labels1,  transform=None):\n",
    "        self.images = images \n",
    "        self.labels1 = labels1\n",
    "\n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Lambda(lambda x: x.repeat(3, 1, 1))  # Grayscale to 3-channel\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx].astype(np.float32)\n",
    "        label1 = int(self.labels1[idx])\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return {\n",
    "            \"pixel_values\": img,\n",
    "            \"labels\": int(label1) if torch.is_tensor(label1) else label1,\n",
    "        }\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55df27b7",
   "metadata": {},
   "source": [
    "#### Preprocessing functions for single distortion and multi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c8c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modified\n",
    "\n",
    "def preprocess_data(data, key='original'):\n",
    "    \"\"\"\n",
    "    Modified from sam's implementation to preprocess 1 set of images. \n",
    "    \n",
    "    key : str (distortion name)\n",
    "    \"\"\"\n",
    "    keys = data.files \n",
    "    print(f'\\nGenerating {key} set')\n",
    "    \n",
    "    images = data[key]\n",
    "    labels = data['label']\n",
    "    \n",
    "    normalized_images = []\n",
    "    for image in images:\n",
    "        normalized_images.append(normalize_images(image))\n",
    "        \n",
    "    labels = np.array(labels)\n",
    "    normalized_images = np.array(normalized_images)\n",
    "    \n",
    "    \n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Images shape: {normalized_images.shape}\")\n",
    "\n",
    "    dataset = ModifiedCustomImageDataset(images=normalized_images, labels1=labels)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96678fde",
   "metadata": {},
   "source": [
    "#### Preprocess data into distinct sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cfb27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 'Uniform_Noise', 'Rotate_90deg', 'Ring_Artifact_v1']\n",
      "\n",
      "Generating Rotate_90deg validataion set\n",
      "Labels shape: (6491, 1)\n",
      "Images shape: (6491, 224, 224)\n",
      "\n",
      "Generating original validataion set\n",
      "Labels shape: (6491, 1)\n",
      "Images shape: (6491, 224, 224)\n",
      "\n",
      "Generating Uniform_Noise validataion set\n",
      "Labels shape: (6491, 1)\n",
      "Images shape: (6491, 224, 224)\n",
      "\n",
      "Generating Ring_Artifact_v1 validataion set\n",
      "Labels shape: (6491, 1)\n",
      "Images shape: (6491, 224, 224)\n",
      "\n",
      "Generating Rotate_90deg validataion set\n",
      "Labels shape: (34561, 1)\n",
      "Images shape: (34561, 224, 224)\n",
      "\n",
      "Generating original validataion set\n",
      "Labels shape: (34561, 1)\n",
      "Images shape: (34561, 224, 224)\n",
      "\n",
      "Generating Uniform_Noise validataion set\n",
      "Labels shape: (34561, 1)\n",
      "Images shape: (34561, 224, 224)\n",
      "\n",
      "Generating Ring_Artifact_v1 validataion set\n"
     ]
    }
   ],
   "source": [
    "val_set_loaded = np.load('val_concatenated_dataset_full.npz')\n",
    "key_list = [key for key in val_set_loaded.files if key != 'label']\n",
    "print(key_list)\n",
    "\n",
    "val_rotate_set = preprocess_data(val_set_loaded, 'Rotate_90deg')\n",
    "val_original_set = preprocess_data(val_set_loaded, 'original')\n",
    "val_noise_set = preprocess_data(val_set_loaded, 'Uniform_Noise')\n",
    "val_ct_set = preprocess_data(val_set_loaded, 'Ring_Artifact_v1')\n",
    "\n",
    "\n",
    "\n",
    "train_set_loaded = np.load('training_concatenated_dataset_full.npz')\n",
    "\n",
    "train_rotate_set = preprocess_data(train_set_loaded, 'Rotate_90deg')\n",
    "train_original_set = preprocess_data(train_set_loaded, 'original')\n",
    "train_noise_set = preprocess_data(train_set_loaded, 'Uniform_Noise')\n",
    "train_ct_set = preprocess_data(train_set_loaded, 'Ring_Artifact_v1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41e8ed8",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888adf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join('A1_Original', 'results')\n",
    "\n",
    "\n",
    "config = ResNetConfig()\n",
    "model = ResNetForMultiLabel(config)\n",
    "\n",
    "print(\"Starting training\")\n",
    "trainer = train_model(\n",
    "    train_dataset=train_original_set,\n",
    "    eval_dataset=val_original_set,\n",
    "    model=model,\n",
    "    output_dir=output_path,  # Checkpoints will go here\n",
    "    num_epochs=100,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"Saving final model\")\n",
    "trainer.save_model(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd87cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join('A4_UNI', 'results')\n",
    "\n",
    "\n",
    "config = ResNetConfig()\n",
    "model = ResNetForMultiLabel(config)\n",
    "\n",
    "print(\"Starting training\")\n",
    "trainer = train_model(\n",
    "    train_dataset=train_noise_set,\n",
    "    eval_dataset=val_noise_set,\n",
    "    model=model,\n",
    "    output_dir=output_path,  # Checkpoints will go here\n",
    "    num_epochs=100,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"Saving final model\")\n",
    "trainer.save_model(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84e9ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join('A2_CT', 'results')\n",
    "\n",
    "\n",
    "config = ResNetConfig()\n",
    "model = ResNetForMultiLabel(config)\n",
    "\n",
    "print(\"Starting training\")\n",
    "trainer = train_model(\n",
    "    train_dataset=train_ct_set,\n",
    "    eval_dataset=val_ct_set,\n",
    "    model=model,\n",
    "    output_dir=output_path,  # Checkpoints will go here\n",
    "    num_epochs=100,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"Saving final model\")\n",
    "trainer.save_model(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec52d043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n",
      "Using GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20328f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join('A3_ROT', 'results')\n",
    "\n",
    "\n",
    "config = ResNetConfig()\n",
    "model = ResNetForMultiLabel(config)\n",
    "\n",
    "print(\"Starting training\")\n",
    "trainer = train_model(\n",
    "    train_dataset=train_rotate_set,\n",
    "    eval_dataset=val_rotate_set,\n",
    "    model=model,\n",
    "    output_dir=output_path,  # Checkpoints will go here\n",
    "    num_epochs=100,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"Saving final model\")\n",
    "trainer.save_model(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7edf36bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'eval_model' from 'resnet' (c:\\Users\\Calvin\\Desktop\\DG\\domain-generalization-ct\\resnet.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-ffdb7b5cc63a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mresnet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0meval_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcheckpoint_directory\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'A1_Original/results/checkpoint-1081'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Load config and model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResNetConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_directory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResNetForMultiLabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'eval_model' from 'resnet' (c:\\Users\\Calvin\\Desktop\\DG\\domain-generalization-ct\\resnet.py)"
     ]
    }
   ],
   "source": [
    "from resnet import eval_model\n",
    "checkpoint_directory= 'A1_Original/results/checkpoint-1081'\n",
    "# Load config and model\n",
    "config = ResNetConfig.from_pretrained(checkpoint_directory)\n",
    "model = ResNetForMultiLabel.from_pretrained(checkpoint_directory, config=config)\n",
    "\n",
    "eval_model(eval_dataset=val_rotate_set, model=model, output_dir=\"A1_Original/val_results\", num_epochs=0, batch_size=32)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1b472f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ResNetForMultiLabel' object has no attribute 'evaluate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-0d0992c07ec6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_dataset\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mval_rotate_set\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Calvin\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1727\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1728\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1729\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Module'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ResNetForMultiLabel' object has no attribute 'evaluate'"
     ]
    }
   ],
   "source": [
    "model.evaluate(eval_dataset =val_rotate_set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a71db6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
